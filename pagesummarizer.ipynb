{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b3fc51524770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file\n",
    "file = open(\"mayowa.txt\",\"r\") \n",
    "data=file.readlines() \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"str(object='') -> str\\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\\n\\nCreate a new string object from the given object. If encoding or\\nerrors is specified, then the object must expose a data buffer\\nthat will be decoded using the given encoding and error handler.\\nOtherwise, returns the result of object.__str__() (if defined)\\nor repr(object).\\nencoding defaults to sys.getdefaultencoding().\\nerrors defaults to 'strict'.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Lowers the case of the input, removes everything inside [] then removes 's and fetches only ascii characters\n",
    "\n",
    "    :param text: blah\n",
    "    :type text: string\n",
    "    :returns: tokens-> blah\n",
    "    :rtype: string\n",
    "\n",
    "    \"\"\"\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", newString)\n",
    "    newString = re.sub(\"'s\",\"\",newString)\n",
    "    newString = re.sub(\"[^'0-9.a-zA-Z]\", \" \", newString)\n",
    "    tokens=newString.split()\n",
    "    return (\" \".join(tokens)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call above function\n",
    "text=[]\n",
    "for i in data:\n",
    "    text.append(preprocessor(i))\n",
    "\n",
    "all_sentences=[]    \n",
    "for i in text:\n",
    "    sentences=i.split(\".\")       \n",
    "    for i in sentences:\n",
    "        if(i!=''):\n",
    "            all_sentences.append(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the sentences for training word2vec\n",
    "tokenized_text = [] \n",
    "for i in all_sentences:\n",
    "    tokenized_text.append(i.split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define word2vec model\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_text,\n",
    "            size=200, # desired no. of features/independent variables \n",
    "            window=5, # context window size\n",
    "            min_count=2,\n",
    "            sg = 0, # 1 for cbow model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            workers= 2, # no.of cores\n",
    "            seed = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19002, 35240)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train word2vec\n",
    "model_w2v.train(tokenized_text, total_examples= len(tokenized_text), epochs=model_w2v.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_vector(tokens, size):\n",
    "    \"\"\"\n",
    "\n",
    "    This function obtains the sentence embedding\n",
    "    \n",
    "    :param tokens: blah\n",
    "    :type tokens: string\n",
    "    :param size: blah\n",
    "    :type size: integer\n",
    "    :returns: vec->blah\n",
    "    :rtype: vector\n",
    "\n",
    "    \"\"\"\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "                         \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#call above function\n",
    "wordvec_arrays = np.zeros((len(tokenized_text), 200))\n",
    "for i in range(len(tokenized_text)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_text[i], 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(wordvec_arrays), len(wordvec_arrays)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute similarity score\n",
    "for i in range(len(wordvec_arrays)):\n",
    "  for j in range(len(wordvec_arrays)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(wordvec_arrays[i].reshape(1,200), wordvec_arrays[j].reshape(1,200))[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a graph\n",
    "nx_graph = nx.from_numpy_array(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute pagerank scores\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the scores\n",
    "sorted_x = sorted(scores.items(), key=lambda kv: kv[1],reverse=True)\n",
    "\n",
    "sent_list=[]\n",
    "for i in sorted_x:\n",
    "    sent_list.append(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highlights for him included hitting a hundred with a swollen jaw and helping india avoid the follow on in the process at georgetown in the drawn first test contributing with a fifty and four catches to india victory in the second test at port of spain india first test victory in west indies since 1975 76 and another fifty in the drawn fourth test with a wicket to boot that of ridley jacobs who was batting on 118. dravid who had been knocking at the doors of indian national cricket team for quite a while with his consistent performance in domestic cricket received his first national call in october 1994 for the last two matches of the wills world series. when dravid joined laxman in the middle on the third day of the test with scoreboard reading 232 4 and india still needing 42 runs to avoid an innings defeat another convincing win for australia looked inevitable. india failed to qualify for the semi finals having lost to australia and new zealand but achieved a consolation victory against pakistan in a tense game what with the military conflict going on between the two countries in kashmir at the same time. dravid arrived in south africa with the indian squad to participate in the 2003 cricket world cup in the capacity of first choice keeper batsman as part of their seven batsmen four bowlers strategy an experiment that had brought success to the team in the past year. the highlight for dravid was 75 runs scored in the tough fourth innings chase of the second test a crucial contribution to india first test win in sri lanka since 1993 despite the absence of key players like tendulkar laxman srinath and kumble. having regained his form on the tour to west indies where he scored a match winning hundred in sabina park jamaica dravid then toured england in what was billed as the series which would decide the world no. he played as designated keeper in six of the 7 match bilateral odi series and effected seven dismissals but fared poorly with the bat as india were handed a 2 5 drubbing by the new zealand. dravid scored 81 runs in the first innings of the third test and took 4 catches in the match as india defeated australia at chennai in a nail biting finish to clinch the series 2 1. dravid scored 85 runs in a match against zimbabwe in the 2000 01 coca cola champions trophy while opening the innings but was forced to miss the rest of the tournament because of an injury. \n"
     ]
    }
   ],
   "source": [
    "#extract top 10 sentences\n",
    "num=10\n",
    "summary=''\n",
    "for i in range(num):\n",
    "    summary=summary+all_sentences[sent_list[i]]+'. '\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
